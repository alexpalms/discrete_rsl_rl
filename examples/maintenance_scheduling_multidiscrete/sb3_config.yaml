name: multidiscrete_PPO_sb3

num_envs: 2048
seed: null

policy_kwargs:
  net_arch: {"pi": [512, 512], "vf": [512, 512]}

gamma: 0.95
learning_rate:
  - 0.00025
  - 0.0000025

# PPO specific
clip_range:
  - 0.15
  - 0.025
n_steps: 32
n_epochs: 4
batch_size: 2048

# Advanced
gae_lambda: 0.95
normalize_advantage: True
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5
use_sde: False
sde_sample_freq: -1
target_kl: null

model_checkpoint_path: null

# Model save conditions
model_save:
  autosave:
    active: true
    frequency: 3000000

# Training stop
training_stop:
  max_time_steps: 15000000