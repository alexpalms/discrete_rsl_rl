name: continuous_PPO_sb3

num_envs: 1024
seed: null

policy_kwargs:
  net_arch: {"pi": [512, 256, 128], "vf": [512, 256, 128]}

gamma: 0.99
learning_rate:
  - 0.0005
  - 0.0005

# PPO specific
clip_range:
  - 0.2
  - 0.2
n_steps: 128
n_epochs: 5
batch_size: 16384

# Advanced
gae_lambda: 0.95
normalize_advantage: True
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5
use_sde: False
sde_sample_freq: -1
target_kl: null

model_checkpoint_path: null

# Model save conditions
model_save:
  autosave:
    active: true
    frequency: 3000000

# Training stop
training_stop:
  max_time_steps: 15000000